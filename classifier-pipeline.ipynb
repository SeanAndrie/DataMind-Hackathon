{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f1b9cc5",
   "metadata": {},
   "source": [
    "# ðŸ§‘â€ðŸ’» Face Recognition Pipeline with InsightFace, Scikit-Learn, and Optuna\n",
    "\n",
    "This notebook implements a face recognition pipeline using InsightFace for feature extraction, and scikit-learn for classification. We also include robust data handling, feature engineering, and hyperparameter tuning using Optuna.\n",
    "\n",
    "âš¡ Key Features:\n",
    "\n",
    "- âœ” Face Detection & Embedding Extraction (InsightFace)\n",
    "- âœ” Enhanced Embeddings with Landmark & Pose Information\n",
    "- âœ” Classification using Ridge Classifier & Linear SVC\n",
    "- âœ” Cross-Validation with Macro F1 & Macro Accuracy\n",
    "- âœ” Hyperparameter Tuning with Optuna\n",
    "- âœ” Robust Test Set Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a5e8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: insightface in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (0.7.3)\n",
      "Requirement already satisfied: optuna in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (4.4.0)\n",
      "Requirement already satisfied: scikit-learn in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: tqdm in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: onnx in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from insightface) (1.18.0)\n",
      "Requirement already satisfied: requests in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from insightface) (2.32.4)\n",
      "Requirement already satisfied: matplotlib in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from insightface) (3.10.3)\n",
      "Requirement already satisfied: Pillow in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from insightface) (10.2.0)\n",
      "Requirement already satisfied: scipy in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from insightface) (1.15.3)\n",
      "Requirement already satisfied: scikit-image in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from insightface) (0.25.2)\n",
      "Requirement already satisfied: easydict in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from insightface) (1.13)\n",
      "Requirement already satisfied: cython in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from insightface) (3.1.2)\n",
      "Requirement already satisfied: albumentations in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from insightface) (2.0.8)\n",
      "Requirement already satisfied: prettytable in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from insightface) (3.16.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from optuna) (1.16.2)\n",
      "Requirement already satisfied: colorlog in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: PyYAML in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: Mako in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
      "Requirement already satisfied: tomli in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from albumentations->insightface) (2.11.7)\n",
      "Requirement already satisfied: albucore==0.0.24 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from albumentations->insightface) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from albumentations->insightface) (4.11.0.86)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from albucore==0.0.24->albumentations->insightface) (3.12.5)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from albucore==0.0.24->albumentations->insightface) (6.4.9)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations->insightface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations->insightface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations->insightface) (0.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from matplotlib->insightface) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from matplotlib->insightface) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from matplotlib->insightface) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from matplotlib->insightface) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from matplotlib->insightface) (3.2.3)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from onnx->insightface) (5.29.5)\n",
      "Requirement already satisfied: wcwidth in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from prettytable->insightface) (0.2.13)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from requests->insightface) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from requests->insightface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from requests->insightface) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from requests->insightface) (2025.6.15)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from scikit-image->insightface) (3.4.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from scikit-image->insightface) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from scikit-image->insightface) (2025.5.10)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages (from scikit-image->insightface) (0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install insightface optuna scikit-learn numpy pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4832411f",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1b44bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import optuna\n",
    "import insightface\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38331c32",
   "metadata": {},
   "source": [
    "# 2. Configuration\n",
    "Define the global configuration dictionary to control detection thresholds, model selection, and feature weighting; set up dataset paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0413607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"APP_MODEL\": \"buffalo_l\",  # Pretrained InsightFace model\n",
    "    \"APP_CONFIG\": {\n",
    "        \"ctx_id\": 0,  # GPU ID (-1 for CPU)\n",
    "        \"det_size\": (320, 320),  # Detection resolution\n",
    "        \"det_thresh\": 0.4,  # Detection threshold\n",
    "    },\n",
    "    \"RANDOM_STATE\": 42,\n",
    "    \"FEATURE_WEIGHTS\": {  # Weights for feature combination\n",
    "        \"embeddings\": 1.0,\n",
    "        \"norm_bbox\": 0.5,\n",
    "    },\n",
    "    \"ENHANCE_EMB\": True  # Whether to use enhanced embeddings\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac2fe37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"dataset\"\n",
    "\n",
    "train_dir = os.path.join(main_dir, \"train\")\n",
    "train_labels_dir = os.path.join(train_dir, \"labels.csv\")\n",
    "test_dir = os.path.join(main_dir, \"test\")\n",
    "unseen_test_dir = os.path.join(main_dir, \"unseen_test\")\n",
    "ref_dir = os.path.join(main_dir, \"reference_faces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d52c9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>emp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>face_0568.jpg</td>\n",
       "      <td>emp016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>face_0433.jpg</td>\n",
       "      <td>emp014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>face_1751.jpg</td>\n",
       "      <td>emp004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>face_0675.jpg</td>\n",
       "      <td>emp028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>face_0112.jpg</td>\n",
       "      <td>emp001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename  emp_id\n",
       "0  face_0568.jpg  emp016\n",
       "1  face_0433.jpg  emp014\n",
       "2  face_1751.jpg  emp004\n",
       "3  face_0675.jpg  emp028\n",
       "4  face_0112.jpg  emp001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv(train_labels_dir)\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713248b8",
   "metadata": {},
   "source": [
    "# 3. Reference & Train Data Creation\n",
    "\n",
    "- Initialize Face Detector (`buffalo_l` from `insightface`)\n",
    "\n",
    "- Setup Robust Face Detection\n",
    "  - Includes multiple strategies for detecting difficult images\n",
    "\n",
    "- Enhance Embeddings with Pose and Landmark features\n",
    "\n",
    "- Create reference and train data from enhanced embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63525a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seang/miniconda3/envs/DataMind/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/seang/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/seang/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/seang/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/seang/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/seang/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (320, 320)\n"
     ]
    }
   ],
   "source": [
    "app = FaceAnalysis(name=CONFIG[\"APP_MODEL\"])\n",
    "app.prepare(**CONFIG[\"APP_CONFIG\"])\n",
    "\n",
    "def robust_face_detection(img, app, attempts=3):\n",
    "    if img is None:\n",
    "        return None\n",
    "        \n",
    "    strategies = [\n",
    "        lambda x: x,  # Original\n",
    "        lambda x: cv2.convertScaleAbs(x, alpha=1.5, beta=40),  # Brighter and higher constrast\n",
    "        lambda x: cv2.equalizeHist(cv2.cvtColor(x, cv2.COLOR_BGR2GRAY))[:,:,np.newaxis].repeat(3,2),  # Normalize pixel intensity\n",
    "        lambda x: cv2.GaussianBlur(x, (5,5), 0),  # De-noise\n",
    "        lambda x: cv2.medianBlur(x, 3),  # Alternative de-noise\n",
    "    ]\n",
    "    \n",
    "    for i in range(attempts):\n",
    "        try:\n",
    "            modified = strategies[i](img) if i < len(strategies) else img\n",
    "            faces = app.get(modified)\n",
    "            if len(faces) > 0:\n",
    "                return faces\n",
    "        except Exception as e:\n",
    "            print(f\"Detection attempt {i+1} failed: {str(e)}\")\n",
    "            continue\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4dad030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_embedding(\n",
    "    embedding, \n",
    "    face, \n",
    "    landmark_weight=0.12,\n",
    "    pose_weight=0.08,\n",
    "    kps_weight=0.05,\n",
    "    det_score_weight=0.04,\n",
    "):\n",
    "    required_attrs = ['bbox', 'kps', 'det_score', 'landmark_2d_106', 'pose']\n",
    "    missing = [attr for attr in required_attrs if not hasattr(face, attr)]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required face attributes: {missing}\")\n",
    "    \n",
    "    base_embed = embedding / (np.linalg.norm(embedding))\n",
    "\n",
    "    bbox_w = face.bbox[2] - face.bbox[0]\n",
    "    bbox_h = face.bbox[3] - face.bbox[1]\n",
    "    if bbox_w <= 0 or bbox_h <= 0:\n",
    "        raise ValueError(\"Invalid bounding box dimensions.\")\n",
    "    \n",
    "    # Predefined key points\n",
    "    landmarks_rel = ((face.landmark_2d_106 - face.bbox[:2]) / [bbox_w, bbox_h]).flatten()\n",
    "    kps_rel = ((face.kps - face.bbox[:2]) / [bbox_w, bbox_h]).flatten()\n",
    "\n",
    "    # Face orientation relative to camera\n",
    "    yaw, pitch, roll = face.pose\n",
    "    yaw_rad = np.deg2rad(yaw)\n",
    "    pitch_rad = np.deg2rad(pitch)\n",
    "    roll_rad = np.deg2rad(roll)\n",
    "    \n",
    "    # Normalize to -1 and 1\n",
    "    norm_pose = np.array([\n",
    "        np.clip(yaw_rad / np.pi, -1, 1),\n",
    "        np.clip(pitch_rad / (np.pi / 2), -1, 1),\n",
    "        np.clip(roll_rad / np.pi, -1, 1)\n",
    "    ])\n",
    "    \n",
    "    enhanced = np.concatenate([\n",
    "        base_embed,\n",
    "        landmark_weight * landmarks_rel,\n",
    "        kps_weight * kps_rel,\n",
    "        pose_weight * norm_pose,\n",
    "        det_score_weight * np.array([face.det_score]),\n",
    "    ])\n",
    "    \n",
    "    return enhanced / (np.linalg.norm(enhanced))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5935646",
   "metadata": {},
   "source": [
    "## Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de4e2f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Reference Identities:   0%|          | 0/34 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing emp001 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  3.16it/s]\n",
      "Processing emp002 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.85it/s]1s/it]\n",
      "Processing emp003 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:03<00:00,  2.92it/s]8s/it]\n",
      "Processing emp004 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.78it/s]0s/it]\n",
      "Processing emp005 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.93it/s]1s/it]\n",
      "Processing emp006 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.06it/s].67s/it]\n",
      "Processing emp007 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.96it/s]7s/it]\n",
      "Processing Reference Identities:  21%|â–ˆâ–ˆ        | 7/34 [00:29<01:54,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not detect any faces in dataset/reference_faces/emp008/emp008_013.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing emp008 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.82it/s]\n",
      "Processing emp009 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  2.87it/s]8s/it]\n",
      "Processing emp010 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.90it/s]0s/it]\n",
      "Processing emp011 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:03<00:00,  2.97it/s]05s/it]\n",
      "Processing emp012 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.91it/s]64s/it]\n",
      "Processing emp013 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:05<00:00,  2.82it/s]69s/it]\n",
      "Processing Reference Identities:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 13/34 [01:00<01:44,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not detect any faces in dataset/reference_faces/emp013/emp013_014.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing emp014 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.82it/s]\n",
      "Processing emp015 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.89it/s]09s/it]\n",
      "Processing emp016 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.88it/s]12s/it]\n",
      "Processing emp017 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.81it/s]15s/it]\n",
      "Processing emp018 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:07<00:00,  2.76it/s]10s/it]\n",
      "Processing emp019 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.94it/s]74s/it]\n",
      "Processing emp020 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.89it/s]55s/it]\n",
      "Processing emp021 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.75it/s]44s/it]\n",
      "Processing emp022 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.85it/s]45s/it]\n",
      "Processing emp023 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.90it/s]39s/it]\n",
      "Processing emp024 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:03<00:00,  2.98it/s]33s/it]\n",
      "Processing emp025 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.85it/s]84s/it]\n",
      "Processing emp026 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  2.88it/s]87s/it]\n",
      "Processing emp027 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.90it/s]18s/it]\n",
      "Processing emp028 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.88it/s]18s/it]\n",
      "Processing emp029 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.88it/s]19s/it]\n",
      "Processing Reference Identities:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 29/34 [02:24<00:24,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not detect any faces in dataset/reference_faces/emp030/emp030_011.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not detect any faces in dataset/reference_faces/emp030/emp030_003.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing emp030 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:04<00:00,  3.15it/s]\n",
      "Processing emp031 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.87it/s]92s/it]\n",
      "Processing emp032 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.91it/s]01s/it]\n",
      "Processing emp034 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:03<00:00,  2.94it/s]05s/it]\n",
      "Processing emp035 folder: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.84it/s]66s/it]\n",
      "Processing Reference Identities: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [02:48<00:00,  4.95s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((448, 512), (448, 738))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_reference_data(ref_dir, ref_labels, app):\n",
    "    ref_data = {\n",
    "        \"embedding\": [],\n",
    "        \"enhanced_embedding\": [],\n",
    "        \"emp_id\": [],\n",
    "        \"norm_bbox\": [],\n",
    "        \"is_ref\": []\n",
    "    }\n",
    "    \n",
    "    for emp_id in tqdm(ref_labels, desc=\"Processing Reference Identities\"):\n",
    "        img_path = os.path.join(ref_dir, emp_id)\n",
    "        if os.path.isdir(img_path) is False:\n",
    "            print(f\"Error processing {emp_id} folder: Is not directory\")\n",
    "            continue\n",
    "        for filename in tqdm(os.listdir(img_path), desc=f\"Processing {emp_id} folder\"):\n",
    "            filepath = os.path.join(img_path, filename)\n",
    "            if filepath.endswith(\".mp4\"):\n",
    "                continue\n",
    "            img = cv2.imread(filepath)\n",
    "            faces = robust_face_detection(img, app, attempts=4)\n",
    "            if faces:\n",
    "                face = faces[0]\n",
    "                img_h, img_w = img.shape[:2]\n",
    "                bbox = face.bbox\n",
    "                norm_bbox = [\n",
    "                    bbox[0]/img_w,\n",
    "                    bbox[1]/img_h,\n",
    "                    bbox[2]/img_w,\n",
    "                    bbox[3]/img_h\n",
    "                ]\n",
    "                ref_data['embedding'].append(\n",
    "                    (face.embedding / np.linalg.norm(face.embedding))\n",
    "                )\n",
    "                ref_data['enhanced_embedding'].append(\n",
    "                    enhance_embedding(face.embedding, face)\n",
    "                )\n",
    "                ref_data['emp_id'].append(emp_id)\n",
    "                ref_data['norm_bbox'].append(norm_bbox)\n",
    "            else:\n",
    "                print(f\"Error: Could not detect any faces in {filepath}\")\n",
    "            ref_data[\"is_ref\"].append(1)\n",
    "    \n",
    "    for key in ref_data:\n",
    "        if key == 'emp_id':\n",
    "            continue\n",
    "        ref_data[key] = np.array(ref_data[key])\n",
    "\n",
    "    return ref_data\n",
    "\n",
    "ref_data = create_reference_data(ref_dir, sorted(os.listdir(ref_dir)), app)\n",
    "ref_data[\"embedding\"].shape, ref_data[\"enhanced_embedding\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f011a6c",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed7192fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Train Identities:   0%|          | 0/1179 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Train Identities: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1179/1179 [06:49<00:00,  2.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1066, 512), (1066, 738))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_train_data(train_dir, labels_df, app, normalize=True):\n",
    "    train_data = {\n",
    "        \"embedding\": [],\n",
    "        \"enhanced_embedding\": [],\n",
    "        \"emp_id\": [],\n",
    "        \"norm_bbox\": [],\n",
    "        \"is_ref\": [],\n",
    "    }\n",
    "    failed_samples = []\n",
    "\n",
    "    img_path = os.path.join(train_dir, \"images\")\n",
    "    for idx, row in tqdm(labels_df.iterrows(), desc=\"Processing Train Identities\", total=len(labels_df)):\n",
    "        filename, emp_id = row\n",
    "        filepath = os.path.join(img_path, filename)\n",
    "        \n",
    "        img = cv2.imread(filepath)\n",
    "        faces = robust_face_detection(img, app, attempts=4)\n",
    "        \n",
    "        if faces:\n",
    "            face = faces[0]\n",
    "            img_h, img_w = img.shape[:2]\n",
    "            bbox = face.bbox\n",
    "            norm_bbox = [\n",
    "                bbox[0]/img_w,\n",
    "                bbox[1]/img_h,\n",
    "                bbox[2]/img_w,\n",
    "                bbox[3]/img_h\n",
    "            ]\n",
    "            train_data['embedding'].append(\n",
    "                (face.embedding / np.linalg.norm(face.embedding))\n",
    "            )\n",
    "            train_data['enhanced_embedding'].append(\n",
    "                enhance_embedding(face.embedding, face)\n",
    "            )\n",
    "            train_data['emp_id'].append(emp_id)\n",
    "            train_data['norm_bbox'].append(norm_bbox)\n",
    "        else:\n",
    "            # train_data['embedding'].append(np.random.normal(0, 0.01, 512))\n",
    "            # train_data['enhanced_embedding'].append(np.random.normal(0, 0.01,738))\n",
    "            # train_data['emp_id'].append(\"UNKNOWN\")\n",
    "            # train_data['norm_bbox'].append([0.0, 0.0, 0.0, 0.0])\n",
    "            failed_samples.append((emp_id, filepath))\n",
    "        \n",
    "        train_data[\"is_ref\"].append(0)\n",
    "    \n",
    "    for key in train_data:\n",
    "        if key == 'emp_id':\n",
    "            continue\n",
    "        train_data[key] = np.array(train_data[key])\n",
    "    \n",
    "    return train_data, failed_samples\n",
    "\n",
    "train_data, train_failed = create_train_data(train_dir, train_labels, app)\n",
    "train_data[\"embedding\"].shape, train_data[\"enhanced_embedding\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19b8c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images used (%): 90.42\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training images used (%): {((len(train_labels) - len(train_failed)) / len(train_labels)) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26838a42",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering\n",
    "\n",
    "- Generate feature vectors combining embeddings and bounding box coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f72862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "def create_feature_vectors(ref_data, scaler, return_target=True, weights=None, enhanced_embedding=False):\n",
    "\n",
    "    if enhanced_embedding:\n",
    "        embeddings = np.array(ref_data[\"enhanced_embedding\"])\n",
    "    else:\n",
    "        embeddings = np.array(ref_data[\"embedding\"])\n",
    "    norm_bbox = np.array(ref_data[\"norm_bbox\"])\n",
    "\n",
    "    features_to_normalize = np.hstack([\n",
    "        norm_bbox\n",
    "    ])\n",
    "\n",
    "    normalized_features = scaler.fit_transform(features_to_normalize)\n",
    "    \n",
    "    norm_bbox = normalized_features[:, :4]\n",
    "\n",
    "    features = np.hstack([\n",
    "        embeddings * weights[\"embeddings\"],        \n",
    "        norm_bbox * weights[\"norm_bbox\"],\n",
    "    ])\n",
    "    \n",
    "    metadata = {\n",
    "        \"emp_ids\": np.array(ref_data[\"emp_id\"]) if return_target else None,\n",
    "        \"feature_names\": [\n",
    "            *[f\"embedding_{i}\" for i in range(512)],\n",
    "            \"bbox_x1\", \"bbox_y1\", \"bbox_x2\", \"bbox_y2\",\n",
    "        ],\n",
    "        \"scaler\": scaler\n",
    "    }\n",
    "    if return_target:\n",
    "        target = ref_data['emp_id']\n",
    "    else:\n",
    "        target = None\n",
    "\n",
    "    return features, target, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "444acc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((448, 742), (1066, 742))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_feats, ref_target, ref_metadata = create_feature_vectors(\n",
    "    ref_data, scaler, weights=CONFIG[\"FEATURE_WEIGHTS\"], enhanced_embedding=CONFIG[\"ENHANCE_EMB\"]\n",
    ")\n",
    "\n",
    "train_feats, train_target, train_metadata = create_feature_vectors(\n",
    "    train_data, scaler, weights=CONFIG[\"FEATURE_WEIGHTS\"], enhanced_embedding=CONFIG[\"ENHANCE_EMB\"]\n",
    ")\n",
    "\n",
    "ref_feats.shape, train_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e0bed",
   "metadata": {},
   "source": [
    "# 5. Prepare Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb62ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(train_target + ref_target)\n",
    "le = LabelEncoder()\n",
    "le.fit(classes)\n",
    "\n",
    "X = np.vstack([train_feats, ref_feats])\n",
    "y = np.hstack([le.transform(train_target), le.transform(ref_target)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafda3a0",
   "metadata": {},
   "source": [
    "# 6. Cross-validation & Evaluation\n",
    "\n",
    "- We employed a 10-fold stratified cross-validation strategy on base models that worked particularly well with high-dimensional embedding. Specifically `RidgeClassifier` and `LinearSVC`. The custom class allows us to cross-validate multiple models at the same time with different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e989f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_cv_summary(results):\n",
    "    for model_name, metrics in results.items():\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        for metric, stats in metrics['mean'].items():\n",
    "            print(f\"  {metric}: {stats:.4f} Â± {metrics['std'][metric]:.4f}\")\n",
    "\n",
    "class CrossValidator:\n",
    "    def __init__(self, models, metric_fns, cv_method, name=None, verbose=True):\n",
    "        self.models = models\n",
    "        self.metric_fns = metric_fns\n",
    "        self.cv_method = cv_method\n",
    "        self.name = name\n",
    "        self.verbose = verbose\n",
    "        self.results = {}\n",
    "\n",
    "    def _calculate_metrics(self, y_true, y_pred):\n",
    "        results = {}\n",
    "        for name, fn in self.metric_fns:\n",
    "            try:\n",
    "                if name == \"macro_f1\":\n",
    "                    results[name] = fn(y_true, y_pred, average=\"macro\")\n",
    "                else:\n",
    "                    results[name] = fn(y_true, y_pred)\n",
    "            except Exception as e:\n",
    "                print(f\"Metric {name} failed: {str(e)}\")\n",
    "                results[name] = np.nan\n",
    "        return results\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.results = {model[0]: [] for model in self.models}\n",
    "        print(f\"Name: {self.name}\\n\")\n",
    "        for fold, (train_idx, test_idx) in enumerate(self.cv_method.split(X, y)):\n",
    "            if self.verbose:\n",
    "                print(f\"\\nFold {fold + 1}/{self.cv_method.n_splits}\")\n",
    "                print(\"-\"*40)\n",
    "            \n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            for name, model in self.models:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                metrics = self._calculate_metrics(y_test, y_pred)\n",
    "                self.results[name].append(metrics)\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f\"- {name}:\")\n",
    "                    for m, v in metrics.items():\n",
    "                        print(f\"  {m}: {v:.4f}\")\n",
    "                    print(\"\\n\")\n",
    "\n",
    "    def summarize(self):\n",
    "        summary = {}\n",
    "        for name in self.results.keys():\n",
    "            fold_results = pd.DataFrame(self.results[name])\n",
    "            summary[name] = {\n",
    "                'mean': fold_results.mean(),\n",
    "                'std': fold_results.std()\n",
    "            }\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b60123e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Optimized Crossvalidation\n",
      "\n",
      "\n",
      "Fold 1/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.9011\n",
      "  macro_accuracy: 0.9149\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.9098\n",
      "  macro_accuracy: 0.9221\n",
      "\n",
      "\n",
      "\n",
      "Fold 2/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.8892\n",
      "  macro_accuracy: 0.9086\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.9022\n",
      "  macro_accuracy: 0.9088\n",
      "\n",
      "\n",
      "\n",
      "Fold 3/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.9164\n",
      "  macro_accuracy: 0.9344\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.9241\n",
      "  macro_accuracy: 0.9380\n",
      "\n",
      "\n",
      "\n",
      "Fold 4/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.9124\n",
      "  macro_accuracy: 0.9188\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.9054\n",
      "  macro_accuracy: 0.9200\n",
      "\n",
      "\n",
      "\n",
      "Fold 5/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.9383\n",
      "  macro_accuracy: 0.9417\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.9302\n",
      "  macro_accuracy: 0.9360\n",
      "\n",
      "\n",
      "\n",
      "Fold 6/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.8670\n",
      "  macro_accuracy: 0.8878\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.8745\n",
      "  macro_accuracy: 0.8922\n",
      "\n",
      "\n",
      "\n",
      "Fold 7/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.8826\n",
      "  macro_accuracy: 0.8848\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.8987\n",
      "  macro_accuracy: 0.8948\n",
      "\n",
      "\n",
      "\n",
      "Fold 8/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.9215\n",
      "  macro_accuracy: 0.9390\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.9137\n",
      "  macro_accuracy: 0.9276\n",
      "\n",
      "\n",
      "\n",
      "Fold 9/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.8228\n",
      "  macro_accuracy: 0.8276\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.8355\n",
      "  macro_accuracy: 0.8280\n",
      "\n",
      "\n",
      "\n",
      "Fold 10/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.9189\n",
      "  macro_accuracy: 0.9243\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.9185\n",
      "  macro_accuracy: 0.9244\n",
      "\n",
      "\n",
      "\n",
      "RidgeClassifier:\n",
      "  macro_f1: 0.8970 Â± 0.0335\n",
      "  macro_accuracy: 0.9082 Â± 0.0344\n",
      "\n",
      "LinearSVC:\n",
      "  macro_f1: 0.9013 Â± 0.0278\n",
      "  macro_accuracy: 0.9092 Â± 0.0325\n"
     ]
    }
   ],
   "source": [
    "def macro_accuracy(y_true, y_pred):\n",
    "    unique_classes = np.unique(y_true)\n",
    "    acc_per_class = []\n",
    "    \n",
    "    for c in unique_classes:\n",
    "        class_mask = y_true == c\n",
    "        correct = np.sum((y_pred == y_true) & class_mask)\n",
    "        acc = correct / np.sum(class_mask)\n",
    "        acc_per_class.append(acc)\n",
    "        \n",
    "    return np.mean(acc_per_class) if acc_per_class else 0\n",
    "\n",
    "models = [\n",
    "    (\"RidgeClassifier\", RidgeClassifier(alpha=1.0, class_weight=\"balanced\", random_state=CONFIG[\"RANDOM_STATE\"])),\n",
    "    (\"LinearSVC\", LinearSVC(class_weight=\"balanced\", random_state=CONFIG[\"RANDOM_STATE\"])),\n",
    "]\n",
    "\n",
    "metric_fns = [\n",
    "    ('macro_f1', f1_score),\n",
    "    ('macro_accuracy', macro_accuracy),\n",
    "]\n",
    "\n",
    "cv = CrossValidator(\n",
    "    models=models, \n",
    "    metric_fns=metric_fns,\n",
    "    cv_method=StratifiedKFold(\n",
    "        n_splits=10, shuffle=True, random_state=CONFIG[\"RANDOM_STATE\"]), \n",
    "    name=\"Optimized Crossvalidation\"\n",
    ")\n",
    "\n",
    "cv.fit(X, y)\n",
    "view_cv_summary(cv.summarize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec60202",
   "metadata": {},
   "source": [
    "# 7. Hyperparameter Tuning\n",
    "\n",
    "- We used `Optuna` to find the best parameters for Ridge and SVC (provided as commented code).\n",
    "\n",
    "Example of setting best parameters manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39e5b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ridge_objective(trial, X, y, cv_method):\n",
    "#     params = {\n",
    "#         'alpha': trial.suggest_float('alpha', 1e-3, 5, log=True),\n",
    "#         'solver': trial.suggest_categorical('solver', ['svd', 'cholesky', 'sparse_cg']),\n",
    "#         'class_weight': trial.suggest_categorical('class_weight', ['balanced']),\n",
    "#         'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "#         'random_state': trial.suggest_categorical('random_state', [CONFIG['RANDOM_STATE']])\n",
    "#     }\n",
    "    \n",
    "#     model = RidgeClassifier(**params)\n",
    "\n",
    "#     fold_scores = []\n",
    "#     for train_idx, valid_idx in cv_method.split(X, y):\n",
    "#         X_train, y_train = X[train_idx], y[train_idx]\n",
    "#         X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_valid)\n",
    "#         fold_scores.append(f1_score(y_valid, y_pred, average=\"macro\"))\n",
    "    \n",
    "#     return np.mean(fold_scores)\n",
    "\n",
    "# def optimize_ridge(X, y, n_trials=50):\n",
    "#     study = optuna.create_study(\n",
    "#         direction='maximize'\n",
    "#     )\n",
    "    \n",
    "#     cv_method = StratifiedKFold(\n",
    "#         n_splits=10,\n",
    "#         shuffle=True,\n",
    "#         random_state=CONFIG[\"RANDOM_STATE\"]\n",
    "#     )\n",
    "    \n",
    "#     study.optimize(\n",
    "#         lambda trial: ridge_objective(trial, X, y, cv_method),\n",
    "#         n_trials=n_trials,\n",
    "#         show_progress_bar=True\n",
    "#     )\n",
    "    \n",
    "#     print(\"Best trial:\")\n",
    "#     trial = study.best_trial\n",
    "#     print(f\"  Macro F1: {trial.value:.4f}\")\n",
    "    \n",
    "#     return study.best_params\n",
    "\n",
    "# best_ridge_params = optimize_ridge(X, y, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71c45df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def linear_svc_objective(trial, X, y, cv_method):\n",
    "#     params = {\n",
    "#         'C': trial.suggest_float('C', 1e-3, 10, log=True),\n",
    "#         'class_weight': trial.suggest_categorical('class_weight', ['balanced']),\n",
    "#         'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "#         'max_iter': trial.suggest_int('max_iter', 500, 5000),\n",
    "#         'dual': trial.suggest_categorical('dual', [True, False]),\n",
    "#         'random_state': trial.suggest_categorical('random_state', [CONFIG['RANDOM_STATE']])\n",
    "#     }\n",
    "    \n",
    "#     model = LinearSVC(**params)\n",
    "\n",
    "#     fold_scores = []\n",
    "#     for train_idx, valid_idx in cv_method.split(X, y):\n",
    "#         X_train, y_train = X[train_idx], y[train_idx]\n",
    "#         X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_valid)\n",
    "#         fold_scores.append(f1_score(y_valid, y_pred, average=\"macro\"))\n",
    "    \n",
    "#     return np.mean(fold_scores)\n",
    "\n",
    "# def optimize_linear_svc(X, y, n_trials=50):\n",
    "#     study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "#     cv_method = StratifiedKFold(\n",
    "#         n_splits=10,\n",
    "#         shuffle=True,\n",
    "#         random_state=CONFIG[\"RANDOM_STATE\"]\n",
    "#     )\n",
    "    \n",
    "#     study.optimize(\n",
    "#         lambda trial: linear_svc_objective(trial, X, y, cv_method),\n",
    "#         n_trials=n_trials,\n",
    "#         show_progress_bar=True\n",
    "#     )\n",
    "    \n",
    "#     print(\"Best trial:\")\n",
    "#     trial = study.best_trial\n",
    "#     print(f\"  Macro F1: {trial.value:.4f}\")\n",
    "#     print(\"  Params:\")\n",
    "#     for k, v in trial.params.items():\n",
    "#         print(f\"    {k}: {v}\")\n",
    "    \n",
    "#     return trial.params\n",
    "\n",
    "# best_linear_svc_params = optimize_linear_svc(X, y, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e33cef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ridge_params = {\n",
    "    'alpha': 0.2538247299320639, \n",
    "    'solver': 'sparse_cg', \n",
    "    'class_weight': 'balanced', \n",
    "    'fit_intercept': True, \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "best_linear_svc_params = {\n",
    "    'C': 0.513724142614831, \n",
    "    'class_weight': 'balanced', \n",
    "    'fit_intercept': True, \n",
    "    'max_iter': 3530, \n",
    "    'dual': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c187f6",
   "metadata": {},
   "source": [
    "## Cross-validation with Optimized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f7945ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: FaceRecognition CV\n",
      "\n",
      "\n",
      "Fold 1/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.9091\n",
      "  macro_accuracy: 0.9221\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.9039\n",
      "  macro_accuracy: 0.9181\n",
      "\n",
      "\n",
      "\n",
      "Fold 2/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.8890\n",
      "  macro_accuracy: 0.9086\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.9226\n",
      "  macro_accuracy: 0.9231\n",
      "\n",
      "\n",
      "\n",
      "Fold 3/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.9184\n",
      "  macro_accuracy: 0.9321\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.9216\n",
      "  macro_accuracy: 0.9380\n",
      "\n",
      "\n",
      "\n",
      "Fold 4/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.9203\n",
      "  macro_accuracy: 0.9224\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.9053\n",
      "  macro_accuracy: 0.9200\n",
      "\n",
      "\n",
      "\n",
      "Fold 5/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.9383\n",
      "  macro_accuracy: 0.9417\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.9389\n",
      "  macro_accuracy: 0.9417\n",
      "\n",
      "\n",
      "\n",
      "Fold 6/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.8705\n",
      "  macro_accuracy: 0.8918\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.8696\n",
      "  macro_accuracy: 0.8922\n",
      "\n",
      "\n",
      "\n",
      "Fold 7/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.8844\n",
      "  macro_accuracy: 0.8858\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.8919\n",
      "  macro_accuracy: 0.8877\n",
      "\n",
      "\n",
      "\n",
      "Fold 8/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.9198\n",
      "  macro_accuracy: 0.9320\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.9180\n",
      "  macro_accuracy: 0.9333\n",
      "\n",
      "\n",
      "\n",
      "Fold 9/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.8395\n",
      "  macro_accuracy: 0.8419\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.8511\n",
      "  macro_accuracy: 0.8550\n",
      "\n",
      "\n",
      "\n",
      "Fold 10/10\n",
      "----------------------------------------\n",
      "- RidgeClassifier:\n",
      "  macro_f1: 0.9166\n",
      "  macro_accuracy: 0.9300\n",
      "\n",
      "\n",
      "- LinearSVC:\n",
      "  macro_f1: 0.9212\n",
      "  macro_accuracy: 0.9244\n",
      "\n",
      "\n",
      "\n",
      "RidgeClassifier:\n",
      "  macro_f1: 0.9006 Â± 0.0296\n",
      "  macro_accuracy: 0.9108 Â± 0.0302\n",
      "\n",
      "LinearSVC:\n",
      "  macro_f1: 0.9044 Â± 0.0269\n",
      "  macro_accuracy: 0.9133 Â± 0.0271\n"
     ]
    }
   ],
   "source": [
    "op_models = [\n",
    "    (\"RidgeClassifier\", RidgeClassifier(**best_ridge_params)),\n",
    "    (\"LinearSVC\", LinearSVC(**best_linear_svc_params))\n",
    "]\n",
    "\n",
    "op_cv = CrossValidator(\n",
    "    models=op_models,\n",
    "    metric_fns=metric_fns,\n",
    "    cv_method=StratifiedKFold(\n",
    "        n_splits=10, shuffle=True, random_state=CONFIG[\"RANDOM_STATE\"]), \n",
    "    name=\"FaceRecognition CV\"\n",
    ")\n",
    "\n",
    "op_cv.fit(X, y)\n",
    "view_cv_summary(op_cv.summarize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed8050b",
   "metadata": {},
   "source": [
    "# 8. Predicting on Test set\n",
    "\n",
    "- Create features for both seen and unseen competition test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6f0342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Test Identites: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 636/636 [03:52<00:00,  2.73it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_test_data(test_dir, app, enhanced_embedding=False):\n",
    "    test_data = {\n",
    "        \"embedding\": [],\n",
    "        \"enhanced_embedding\": [],\n",
    "        \"norm_bbox\": [],\n",
    "        \"filenames\": []\n",
    "    }\n",
    "    \n",
    "    failed_samples = []\n",
    "    img_path = os.path.join(test_dir, \"images\")\n",
    "    for filename in tqdm(sorted(os.listdir(img_path)), desc=\"Processing Test Identites\"):\n",
    "        filepath = os.path.join(img_path, filename)\n",
    "        \n",
    "        img = cv2.imread(filepath)\n",
    "        faces = robust_face_detection(img, app, attempts=4)\n",
    "\n",
    "        if faces:\n",
    "            face = faces[0]\n",
    "            img_h, img_w = img.shape[:2]\n",
    "            bbox = face.bbox\n",
    "            norm_bbox = [\n",
    "                bbox[0]/img_w,\n",
    "                bbox[1]/img_h,\n",
    "                bbox[2]/img_w,\n",
    "                bbox[2]/img_h\n",
    "            ]\n",
    "            test_data['embedding'].append(\n",
    "                (face.embedding / np.linalg.norm(face.embedding))\n",
    "            )\n",
    "            test_data['enhanced_embedding'].append(\n",
    "                enhance_embedding(face.embedding, face)\n",
    "            )\n",
    "            test_data['norm_bbox'].append(norm_bbox)\n",
    "        else:\n",
    "            test_data['embedding'].append(np.zeros(512))\n",
    "            test_data['enhanced_embedding'].append(np.zeros(738))\n",
    "            test_data['norm_bbox'].append([-1.0, -1.0, -1.0, -1.0])\n",
    "            failed_samples.append((filepath))\n",
    "        test_data['filenames'].append(filename)\n",
    "\n",
    "    for key in test_data:\n",
    "        if key == 'filenames':\n",
    "            continue\n",
    "        test_data[key] = np.array(test_data[key])\n",
    "    \n",
    "    return test_data, failed_samples\n",
    "\n",
    "test_data, test_failed = create_test_data(test_dir, app, enhanced_embedding=CONFIG[\"ENHANCE_EMB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34bdc6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Test Identites: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1884/1884 [12:10<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "unseen_test_data, unseen_test_failed = create_test_data(unseen_test_dir, app, enhanced_embedding=CONFIG[\"ENHANCE_EMB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8edea63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((636, 512), (636, 738))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['embedding'].shape, test_data['enhanced_embedding'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "662fdbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1884, 512), (1884, 738))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_test_data['embedding'].shape, unseen_test_data['enhanced_embedding'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be3f5f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(636, 742)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feats, _, test_metadata = create_feature_vectors(\n",
    "    test_data, scaler, weights=CONFIG[\"FEATURE_WEIGHTS\"], enhanced_embedding=CONFIG[\"ENHANCE_EMB\"], return_target=False\n",
    ")\n",
    "test_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b1f187d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(636, 742)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_test_feats, _, unseen_test_metadata = create_feature_vectors(\n",
    "    unseen_test_data, scaler, weights=CONFIG[\"FEATURE_WEIGHTS\"], enhanced_embedding=CONFIG[\"ENHANCE_EMB\"], return_target=False\n",
    ")\n",
    "test_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1c7f4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  4,  4,  4,  4,  0,  4,  4,  4, 22, 22,  4, 11, 14,  4,  4, 14,\n",
       "       12,  2, 21])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = RidgeClassifier(**best_ridge_params)\n",
    "ridge.fit(X, y)\n",
    "\n",
    "ridge_preds = ridge.predict(unseen_test_feats)\n",
    "ridge_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc9cf239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  4,  4,  4,  4,  0,  4,  4,  4, 22, 22,  4, 11, 14,  4,  4, 14,\n",
       "       12,  2, 21])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(**best_linear_svc_params)\n",
    "svc.fit(X, y)\n",
    "\n",
    "svc_preds = svc.predict(unseen_test_feats)\n",
    "svc_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53afa72f",
   "metadata": {},
   "source": [
    "# 9. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d6eff7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>employee_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>face_10000.jpg</td>\n",
       "      <td>emp014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>face_10001.jpg</td>\n",
       "      <td>emp004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>face_10002.jpg</td>\n",
       "      <td>emp004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>face_10003.jpg</td>\n",
       "      <td>emp004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>face_10004.jpg</td>\n",
       "      <td>emp004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>face_10005.jpg</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>face_10006.jpg</td>\n",
       "      <td>emp004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>face_10007.jpg</td>\n",
       "      <td>emp004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>face_10008.jpg</td>\n",
       "      <td>emp004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>face_10009.jpg</td>\n",
       "      <td>emp022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename employee_id\n",
       "0  face_10000.jpg      emp014\n",
       "1  face_10001.jpg      emp004\n",
       "2  face_10002.jpg      emp004\n",
       "3  face_10003.jpg      emp004\n",
       "4  face_10004.jpg      emp004\n",
       "5  face_10005.jpg     unknown\n",
       "6  face_10006.jpg      emp004\n",
       "7  face_10007.jpg      emp004\n",
       "8  face_10008.jpg      emp004\n",
       "9  face_10009.jpg      emp022"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(columns=[\"filename\", \"employee_id\"])\n",
    "submission[\"filename\"] = unseen_test_data['filenames']\n",
    "submission[\"employee_id\"] = le.classes_[ridge_preds]\n",
    "\n",
    "# Lowercase any \"UNKNOWN\" labels\n",
    "submission[\"employee_id\"] = submission[\"employee_id\"].apply(\n",
    "    lambda x: x.lower() if x == \"UNKNOWN\" else x\n",
    ")\n",
    "\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e18a6d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
